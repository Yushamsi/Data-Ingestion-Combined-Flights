{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMOs1hXfbYIMT9Q8o5lKYP+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Yushamsi/Data-Ingestion-Combined-Flights/blob/main/Data-Ingestion.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# *Data Ingestion*"
      ],
      "metadata": {
        "id": "mZJfeGJpeMi3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KmcHCAhRbq_y"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import dask.dataframe as dd\n",
        "import modin.pandas as mpd\n",
        "import os\n",
        "import psutil\n",
        "import time\n",
        "import yaml\n",
        "import testutility as util"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# File path\n",
        "file_path = 'your_large_file.csv'"
      ],
      "metadata": {
        "id": "JGV8gUTZhNfb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Reading the file"
      ],
      "metadata": {
        "id": "8EnalQajiw8n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to measure CPU and memory usage\n",
        "def measure_usage(library_name, read_function, file_path):\n",
        "    # Measure before reading\n",
        "    start_cpu = psutil.cpu_percent(interval=1)\n",
        "    start_memory = psutil.virtual_memory().used / (1024 ** 3)  # Convert to GB\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Read file\n",
        "    df = read_function(file_path)\n",
        "\n",
        "    # Measure after reading\n",
        "    end_cpu = psutil.cpu_percent(interval=1)\n",
        "    end_memory = psutil.virtual_memory().used / (1024 ** 3)  # Convert to GB\n",
        "    end_time = time.time()\n",
        "\n",
        "    # Calculate differences\n",
        "    cpu_usage = end_cpu - start_cpu\n",
        "    memory_usage = end_memory - start_memory\n",
        "    read_time_seconds = end_time - start_time\n",
        "    read_time_minutes = read_time_seconds / 60\n",
        "\n",
        "    # Print results\n",
        "    print(f\"{library_name} read time: {read_time_seconds:.2f} seconds ({read_time_minutes:.2f} minutes)\")\n",
        "    print(f\"{library_name} CPU usage change: {cpu_usage:.2f}%\")\n",
        "    print(f\"{library_name} Memory usage change: {memory_usage:.2f} GB\")"
      ],
      "metadata": {
        "id": "Zkhfv54OhH-R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Reading with Pandas"
      ],
      "metadata": {
        "id": "LOdTT0ADfoAd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Measure Pandas\n",
        "measure_usage(\"Pandas\", pd.read_csv, file_path)"
      ],
      "metadata": {
        "id": "PdcUKPP1eoFI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Reading with Dask\n"
      ],
      "metadata": {
        "id": "YVV7WDMHfuig"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# For Dask since the actual data loading operation (like converting to pandas DataFrame) happens when you perform an action (like compute for Dask), the direct approach works differently.\n",
        "# For these, typically need to wrap the operation in a function if you're doing more than just reading.\n",
        "measure_usage(\"Dask\", lambda file: dd.read_csv(file).compute(), file_path)"
      ],
      "metadata": {
        "id": "1Xvm_XyXek6-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Reading with Modin (Pandas on Ray)"
      ],
      "metadata": {
        "id": "BCrATr0bfzY3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Modin with Ray\n",
        "os.environ[\"MODIN_ENGINE\"] = \"ray\"  # Use Ray as the backend\n",
        "measure_usage(\"Modin Ray\", mpd.read_csv, file_path)\n"
      ],
      "metadata": {
        "id": "VKGss1_teiU2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Reading with Modin (Pandas on Ray)"
      ],
      "metadata": {
        "id": "QZOSbnvVf6xR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Modin with Dask\n",
        "os.environ[\"MODIN_ENGINE\"] = \"dask\"  # Use Dask as the backend\n",
        "measure_usage(\"Modin Dask\", mpd.read_csv, file_path)"
      ],
      "metadata": {
        "id": "_U07U4XBfWG6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Cleaning Data"
      ],
      "metadata": {
        "id": "t0fEStHqpPZe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_column_names(df):\n",
        "    df.columns = df.columns.str.strip()\n",
        "    df.columns = df.columns.str.replace(' ', '_', regex=True)\n",
        "    df.columns = df.columns.str.replace('[^\\\\w\\\\s]', '', regex=True)\n",
        "    return df"
      ],
      "metadata": {
        "id": "EnqeZka0ozBW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply the function to your DataFrame\n",
        "df = clean_column_names(df)\n",
        "\n",
        "# Display the cleaned column names\n",
        "print(df.columns)"
      ],
      "metadata": {
        "id": "FggEamHvpVWN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#YAML"
      ],
      "metadata": {
        "id": "LgRC3Jj0si21"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile schema.yaml\n",
        "file_type: csv\n",
        "dataset_name: testfile\n",
        "file_name: test_data\n",
        "inbound_delimiter: \",\"\n",
        "outbound_delimiter: \"|\"\n",
        "skip_leading_rows: 1\n",
        "columns:\n",
        "    - city\n",
        "    - price\n",
        "    - distance"
      ],
      "metadata": {
        "id": "Kz18fWIwskQ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the YAML schema\n",
        "config_data = util.read_config_file(\"file.yaml\")\n",
        "\n",
        "# Access file settings and column names from the schema\n",
        "read_separator = config_data['inbound_delimiter']\n",
        "write_separator = config_data['outbound_delimiter']\n",
        "columns = config_data['columns']\n",
        "\n",
        "print(f\"Read Separator: {read_separator}\")\n",
        "print(f\"Write Separator: {write_separator}\")\n",
        "print(f\"Columns: {columns}\")\n"
      ],
      "metadata": {
        "id": "0c0f9A4NslT5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Comparing Schema File to DF"
      ],
      "metadata": {
        "id": "j7bgntm6t_EQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "util.col_header_val(df, config_data)"
      ],
      "metadata": {
        "id": "PpLAkikruHUl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Columns of DF are:\" , df.columns)\n",
        "print(\"Columns of YAML are:\" , config_data['columns'])"
      ],
      "metadata": {
        "id": "DnkyJ5iuuVmM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if util.col_header_val(df, config_data) == 0:\n",
        "    print(\"validation failed\")\n",
        "    # write code to reject the file\n",
        "else:\n",
        "    print(\"col validation passed\")\n",
        "    # write the code to perform further action\n",
        "    # in the pipleine"
      ],
      "metadata": {
        "id": "HuWzngshupDU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}